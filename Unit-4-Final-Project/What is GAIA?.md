# ğŸ§  What is GAIA?

**GAIA** (General AI Assistant) is a **benchmark** designed to test AI agents on **real-world tasks** requiring:

* ğŸ” Multi-step reasoning
* ğŸ–¼ï¸ Multimodal understanding
* ğŸŒ Web browsing
* ğŸ› ï¸ Effective tool use

Introduced in the paper [*â€œGAIA: A Benchmark for General AI Assistants,â€*](https://huggingface.co/papers/2311.12983) it sets a high bar for measuring progress toward **truly general-purpose AI assistants**.

---

## ğŸ“Š Human vs. AI Performance

| Participant               | Accuracy                    |
| ------------------------- | --------------------------- |
| ğŸ§‘ Humans                 | \~92%                       |
| ğŸ¤– GPT-4 (with plugins)   | \~15%                       |
| ğŸ§ª Deep Research (OpenAI) | **67.36%** (validation set) |

> GAIA tasks are **easy for humans**, but **highly challenging for current AI systems**.

---

## ğŸŒ± Core Principles of GAIA

GAIA is built on four key pillars:

* **ğŸ” Real-world difficulty**: Tasks require multi-step reasoning, multimodal understanding, and tool interaction.
* **ğŸ§¾ Human interpretability**: Clear and understandable questions.
* **ğŸ›¡ï¸ Non-gameability**: No shortcutsâ€”answers require full task completion.
* **ğŸ§° Simple evaluation**: Concise, factual responses for easy benchmarking.

---

## ğŸ§© Difficulty Levels

GAIA tasks are categorized by complexity:

| Level | Description                                 |
| ----- | ------------------------------------------- |
| 1ï¸âƒ£   | <5 steps, minimal tools                     |
| 2ï¸âƒ£   | 5â€“10 steps, multiple tools                  |
| 3ï¸âƒ£   | Long-term planning and advanced integration |

---

## ğŸ§  Example of a Hard GAIA Question

> *â€œWhich of the fruits shown in the 2008 painting â€˜Embroidery from Uzbekistanâ€™ were served as part of the October 1949 breakfast menu for the ocean liner later used as a prop in the film â€˜The Last Voyageâ€™? Give the items as a comma-separated list, ordered clockwise from 12 oâ€™clock. Use plural forms.â€*

### Challenges:

* ğŸ–¼ï¸ Multimodal reasoning (visual recognition)
* ğŸ•µï¸ Multi-hop retrieval (painting â†’ film â†’ ship â†’ menu)
* ğŸ§  Sequencing and structured output

This kind of task highlights where standalone LLMs often fall short, making GAIA an ideal benchmark for **agent-based systems** that can reason, retrieve, and execute over multiple steps and modalities.
![GIGA Benchmark](../assets/gaia_capabilities.png)

---

## ğŸ“ˆ GAIA in Action

* **Live Evaluation**: Submit your agent on the public **GAIA Leaderboard** via [Hugging Face](https://huggingface.co/gaia-benchmark)
* **Test Set**: 300 real-world tasks designed to push the limits of current AI

---

## ğŸ“š Want to Learn More?

* [ğŸ“„ GAIA Paper](https://huggingface.co/papers/2311.12983)
* [ğŸ“¢ OpenAI Deep Research Release](https://openai.com/index/introducing-deep-research/)
* [ğŸ› ï¸ Open-source DeepResearch Tools](https://huggingface.co/blog/open-deep-research)
